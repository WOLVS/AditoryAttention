{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fdba99-46f4-4950-a8e8-a7cc94f2670d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d937dd13-e702-4894-b903-0f856773a52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1accessing importing the files\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a7e6a4-ed9b-4dc1-b70e-5c50e7173734",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2accessing the files.\n",
    "root_path = r\"C:\\Users\\xtwf7586\\OneDrive - University of Leeds\\fnirs\\AuditoryRecording13032025\"\n",
    "all_folders = [f\"2025-03-13_{i:03d}\" for i in range(1, 14) if i != 2]\n",
    "print(\"Folders to be loaded:\")\n",
    "print(all_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cf67fe-ebaf-4214-bece-9ad45382f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3accessing all the files of the participants and getting their duration\n",
    "participant_data = {f\"participant_{i+1}\": [] for i in range(3)}\n",
    "\n",
    "for idx, folder_name in enumerate(all_folders):\n",
    "    folder_path = os.path.join(root_path, folder_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        continue\n",
    "    snirf_files = [f for f in os.listdir(folder_path) if f.endswith(\".snirf\")]\n",
    "    if not snirf_files:\n",
    "        print(f\"No .snirf file found in {folder_path}\")\n",
    "        continue\n",
    "    snirf_path = os.path.join(folder_path, snirf_files[0])\n",
    "    print(f\"Loading {snirf_path}\")\n",
    "    raw = mne.io.read_raw_snirf(snirf_path, preload=True)\n",
    "    participant_idx = idx // 4\n",
    "    participant_key = f\"participant_{participant_idx + 1}\"\n",
    "    participant_data[participant_key].append(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fefd6c5-4477-42bd-9a2e-41b18fbfb5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all 4 files from all 3 participants, getting their sampling frequency and durations.\n",
    "for key, files in participant_data.items():\n",
    "    print(f\"{key}: {len(files)} SNIRF files loaded\")\n",
    "\n",
    "for participant, raws in participant_data.items():\n",
    "    print(f\"\\n=== {participant} ===\")\n",
    "    for i, raw in enumerate(raws):\n",
    "        print(f\"File {i+1}: Channels={len(raw.ch_names)}, Duration={raw.times[-1]:.2f}s, Sampling Frequency={raw.info['sfreq']:.2f} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bed61b-07c3-4592-9570-7f15446c719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "from mne.preprocessing.nirs import source_detector_distances\n",
    "\n",
    "print(\"\\n--- Checking source-detector distances ---\")\n",
    "\n",
    "for participant, raws in participant_data.items():\n",
    "    print(f\"\\n=== {participant} ===\")\n",
    "    for i, raw in enumerate(raws):\n",
    "        print(f\"\\nFile {i+1}:\")\n",
    "        try:\n",
    "            distances = source_detector_distances(raw.info)\n",
    "            short_channels = distances < 0.015  # 1.5 cm threshold\n",
    "\n",
    "            if np.any(short_channels):\n",
    "                print(f\"  Short channels found: {np.sum(short_channels)}\")\n",
    "                for idx, is_short in enumerate(short_channels):\n",
    "                    if is_short:\n",
    "                        print(f\"    Channel {raw.ch_names[idx]} — Distance: {distances[idx]*100:.2f} cm\")\n",
    "            else:\n",
    "                print(\"  No short channels found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Could not compute distances: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078ab862-e4ef-4ebb-b8a7-864b17b8c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "from mne.preprocessing.nirs import source_detector_distances\n",
    "\n",
    "print(\"\\n--- Source-Detector Distances (in cm) ---\")\n",
    "\n",
    "for participant, raws in participant_data.items():\n",
    "    print(f\"\\n=== {participant} ===\")\n",
    "    for i, raw in enumerate(raws):\n",
    "        print(f\"\\nFile {i+1}:\")\n",
    "        try:\n",
    "            distances = source_detector_distances(raw.info)\n",
    "            for ch_name, dist in zip(raw.ch_names, distances):\n",
    "                print(f\"  {ch_name}: {dist*100:.2f} cm\")  # convert meters to cm\n",
    "        except Exception as e:\n",
    "            print(f\"  Could not compute distances: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914a30c8-69be-47a0-aaf3-fba837a1c794",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.preprocessing.nirs import source_detector_distances\n",
    "\n",
    "#\n",
    "raw_example = participant_data[\"participant_1\"][0]\n",
    "distances = source_detector_distances(raw_example.info) * 100  # convert to cm\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(len(distances)), distances)\n",
    "plt.xticks(range(len(distances)), raw_example.ch_names, rotation=90)\n",
    "plt.ylabel(\"Source-Detector Distance (cm)\")\n",
    "plt.title(\"Channel-wise Source-Detector Distances\")\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcae2dcd-b2a0-4571-adce-0e2a7c97a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8\n",
    "raw_example = participant_data[\"participant_1\"][0]\n",
    "\n",
    "# 2D plot (top-down view)\n",
    "raw_example.plot_sensors(kind='topomap', show_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca001ad3-3342-429c-afde-0c3ed5de6fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mne.preprocessing.nirs import source_detector_distances\n",
    "\n",
    "raw = participant_data[\"participant_1\"][0]\n",
    "\n",
    "\n",
    "positions = []\n",
    "labels = []\n",
    "seen_pairs = set()\n",
    "\n",
    "for ch in raw.info['chs']:\n",
    "    loc = ch['loc'][:3]  # x, y, z\n",
    "    label = ch['ch_name']\n",
    "    sd_pair = label.split()[0]  # 'S1_D1'\n",
    "    if sd_pair not in seen_pairs:\n",
    "        seen_pairs.add(sd_pair)\n",
    "        positions.append(loc)\n",
    "        labels.append(sd_pair)\n",
    "\n",
    "positions = np.array(positions)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(positions[:, 0], positions[:, 1])\n",
    "for i, txt in enumerate(labels):\n",
    "    ax.annotate(txt, (positions[i, 0], positions[i, 1]), fontsize=8)\n",
    "ax.set_title(\"fNIRS Sensor Layout (Unique SD Pairs)\")\n",
    "ax.set_xlabel(\"X\")\n",
    "ax.set_ylabel(\"Y\")\n",
    "ax.grid(True)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b05b3c9-890a-4263-afb8-0f4a852fce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the plotting\n",
    "def plot_first_n_channels(raw, n=10, title=\"\"):\n",
    "    data, times = raw[:n, :]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for ch_i in range(data.shape[0]):\n",
    "        plt.plot(times, data[ch_i] + ch_i*1e-4, label=f'Ch {ch_i+1}')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (offset for clarity)\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a1c1dc-1bca-4305-90f2-f2c99cdbdd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9plotting all 40 channels from all 4 recordings in all 3 participants.\n",
    "fig, axs = plt.subplots(nrows=3, ncols=4, figsize=(24, 12), sharex=False, sharey=False)\n",
    "\n",
    "for i, (participant, raws) in enumerate(participant_data.items()):\n",
    "    for j, raw in enumerate(raws):\n",
    "        data, times = raw[:, :]\n",
    "        ax = axs[i, j]\n",
    "        for ch in range(data.shape[0]):\n",
    "            offset = ch * 1e-6\n",
    "            ax.plot(times, data[ch] + offset)\n",
    "        ax.set_title(f\"{participant} - File {j+1}\")\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"Amplitude + offset\")\n",
    "        ax.set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"All 40 fNIRS Channels Across 4 Recordings per Participant\", fontsize=18, y=1.02)\n",
    "plt.show()\n",
    "# mne generate the data by thier syntheize adding dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7dff8-e634-4d22-8f82-12bc4c0a8267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "from collections import defaultdict\n",
    "from mne.preprocessing.nirs import optical_density\n",
    "\n",
    "cv_threshold = 7.5  # from the automated named study in percent\n",
    "participant_raw_cv_filtered = {}\n",
    "participant_raw_cv_rejected = {}  # <-- new dict to store bad channels\n",
    "\n",
    "for participant, raws in participant_data.items():\n",
    "    participant_raw_cv_filtered[participant] = []\n",
    "    participant_raw_cv_rejected[participant] = []\n",
    "\n",
    "    for i, raw in enumerate(raws):\n",
    "        data = raw.get_data()\n",
    "        mean = np.mean(data, axis=1)\n",
    "        std = np.std(data, axis=1)\n",
    "        cv = 100 * std / mean\n",
    "\n",
    "        # Group by S-D pair (ignoring wavelength)\n",
    "        pair_map = defaultdict(list)\n",
    "        for idx, ch_name in enumerate(raw.ch_names):\n",
    "            pair_id = \" \".join(ch_name.split()[:-1])  # e.g., \"S1_D1\"\n",
    "            pair_map[pair_id].append(idx)\n",
    "\n",
    "        good_idx, bad_idx = [], []\n",
    "        for pair_id, indices in pair_map.items():\n",
    "            if len(indices) == 2:\n",
    "                if all(cv[idx] < cv_threshold for idx in indices):\n",
    "                    good_idx.extend(indices)\n",
    "                else:\n",
    "                    bad_idx.extend(indices)\n",
    "\n",
    "        # Store filtered (good) and rejected (bad) Raw objects\n",
    "        good_chs = [raw.ch_names[idx] for idx in good_idx]\n",
    "        bad_chs = [raw.ch_names[idx] for idx in bad_idx]\n",
    "\n",
    "        raw_good = raw.copy().pick(good_chs)\n",
    "        raw_bad = raw.copy().pick(bad_chs)\n",
    "\n",
    "        participant_raw_cv_filtered[participant].append(raw_good)\n",
    "        participant_raw_cv_rejected[participant].append(raw_bad)\n",
    "\n",
    "        print(f\"{participant} File {i+1}: Kept {len(good_chs)} | Dropped {len(bad_chs)} channels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c832e-9c27-412d-b8f7-9048a8022bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "participant_od_good = {}\n",
    "participant_od_bad = {}\n",
    "\n",
    "for participant in participant_raw_cv_filtered:\n",
    "    participant_od_good[participant] = []\n",
    "    participant_od_bad[participant] = []\n",
    "\n",
    "    for i in range(len(participant_raw_cv_filtered[participant])):\n",
    "        raw_good = participant_raw_cv_filtered[participant][i]\n",
    "        raw_bad = participant_raw_cv_rejected[participant][i]\n",
    "\n",
    "        od_good = optical_density(raw_good)\n",
    "        od_bad = optical_density(raw_bad)\n",
    "\n",
    "        participant_od_good[participant].append(od_good)\n",
    "        participant_od_bad[participant].append(od_bad)\n",
    "\n",
    "        print(f\"Plotting GOOD: {participant} - File {i+1}\")\n",
    "        od_good.plot(title=f\"{participant} - File {i+1} (GOOD Channels)\")\n",
    "    \n",
    "\n",
    "        print(f\"Plotting BAD: {participant} - File {i+1}\")\n",
    "        od_bad.plot(title=f\"{participant} - File {i+1} (BAD Channels)\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6766a5-d779-49e4-85eb-db5a7e4197bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant, od_list in participant_od_good.items():\n",
    "    print(f\"\\n=== {participant} ===\")\n",
    "    for i, raw_od in enumerate(od_list):\n",
    "        n_channels = len(raw_od.ch_names)\n",
    "        print(f\"File {i+1}: {n_channels} OD channels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25aaeab8-72ec-4e40-9163-66a35496f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def plot_sd_pairs_with_task_overlay(raw_od, attention_start=34.5, attention_end=76.5, max_pairs=None):\n",
    "  \n",
    "    data, times = raw_od.get_data(return_times=True)\n",
    "    ch_names = raw_od.ch_names\n",
    "\n",
    "    # Group channel indices by S-D pair ID (e.g., \"S3_D4\")\n",
    "    sd_pair_map = defaultdict(dict)\n",
    "    for idx, ch_name in enumerate(ch_names):\n",
    "        parts = ch_name.split()\n",
    "        sd_id = parts[0]  # e.g., \"S3_D4\"\n",
    "        wl = parts[1]     # e.g., \"760\" or \"850\"\n",
    "        sd_pair_map[sd_id][wl] = idx\n",
    "\n",
    "    plotted = 0\n",
    "    for sd_id, wl_map in sd_pair_map.items():\n",
    "        if \"760\" in wl_map and \"850\" in wl_map:\n",
    "            idx_760 = wl_map[\"760\"]\n",
    "            idx_850 = wl_map[\"850\"]\n",
    "\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.plot(times, data[idx_760], label=f\"{sd_id} 760 nm\", color='blue')\n",
    "            plt.plot(times, data[idx_850], label=f\"{sd_id} 850 nm\", color='green')\n",
    "            plt.axvspan(attention_start, attention_end, color='red', alpha=0.2, label='Attention Period')\n",
    "            plt.title(f\"S-D Pair: {sd_id}\")\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Optical Density\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "             #  Closes the figure to prevent buildup\n",
    "\n",
    "\n",
    "            plotted += 1\n",
    "            if max_pairs is not None and plotted >= max_pairs:\n",
    "                break\n",
    "for participant in participant_od_good:\n",
    "    for i in range(len(participant_od_good[participant])):\n",
    "        print(f\"\\nInspecting GOOD channels: {participant} - File {i+1}\")\n",
    "        plot_sd_pairs_with_task_overlay(\n",
    "            participant_od_good[participant][i],\n",
    "            attention_start=34.5,\n",
    "            attention_end=76.5,\n",
    "       \n",
    "        )\n",
    "\n",
    "        print(f\"\\nInspecting BAD channels: {participant} - File {i+1}\")\n",
    "        plot_sd_pairs_with_task_overlay(\n",
    "            participant_od_bad[participant][i],\n",
    "            attention_start=34.5,\n",
    "            attention_end=76.5,\n",
    "\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b003ec5b-740a-47d3-bcc7-131a8360dfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# Final hand-picked S-D pairs per participant\n",
    "final_channels = {\n",
    "    \"participant_1\": [\n",
    "        \"S3_D3\", \"S3_D4\", \"S4_D4\", \"S5_D3\", \"S6_D4\", \"S6_D5\", \"S6_D6\", \"S7_D5\", \"S8_D6\"\n",
    "    ],\n",
    "    \"participant_2\": [\n",
    "        \"S2_D1\", \"S3_D3\", \"S3_D4\", \"S4_D4\", \"S5_D3\", \"S6_D4\", \"S6_D5\", \"S6_D6\", \"S7_D5\", \"S8_D6\"\n",
    "    ],\n",
    "    \"participant_3\": [\n",
    "        \"S1_D1\", \"S2_D1\", \"S3_D3\", \"S3_D4\", \"S4_D2\", \"S4_D4\", \"S5_D3\", \"S6_D4\", \"S6_D5\", \"S6_D6\",\n",
    "        \"S7_D5\", \"S7_D7\", \"S8_D6\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "# Prepare new dictionary\n",
    "participant_od_final = {}\n",
    "\n",
    "# Loop through participants\n",
    "for participant in participant_od_good.keys():\n",
    "    final_list = []\n",
    "    for i in range(len(participant_od_good[participant])):\n",
    "\n",
    "        # Combine good and bad channels\n",
    "        combined_raw = participant_od_good[participant][i].copy().add_channels(\n",
    "            [participant_od_bad[participant][i].copy()],\n",
    "            force_update_info=True\n",
    "        )\n",
    "\n",
    "        # Map S-D IDs to their channel indices\n",
    "        ch_names = combined_raw.ch_names\n",
    "        channel_map = defaultdict(list)\n",
    "        for idx, name in enumerate(ch_names):\n",
    "            parts = name.split()\n",
    "            sd_id = parts[0]  # e.g., \"S3_D4\"\n",
    "            wl = parts[1]     # e.g., \"760\"\n",
    "            channel_map[sd_id].append(idx)\n",
    "\n",
    "        # Collect indices of final desired channels\n",
    "        desired_channels = final_channels[participant]\n",
    "                # Enforce correct ordering of S-D pairs\n",
    "        indices_to_keep = []\n",
    "        for sd_pair in final_channels[participant]:\n",
    "            if sd_pair in channel_map:\n",
    "                # Always add 760 first, then 850 for consistency\n",
    "                wl_sorted = sorted(channel_map[sd_pair], key=lambda idx: combined_raw.ch_names[idx].split()[1])\n",
    "\n",
    "                indices_to_keep.extend(wl_sorted)\n",
    "\n",
    "\n",
    "        # Pick final channels\n",
    "        raw_selected = combined_raw.copy().pick(indices_to_keep)\n",
    "        final_list.append(raw_selected)\n",
    "\n",
    "    participant_od_final[participant] = final_list\n",
    "\n",
    "# 🧾 Display in readable format using pandas\n",
    "rows = []\n",
    "for participant, recordings in participant_od_final.items():\n",
    "    for i, raw in enumerate(recordings):\n",
    "        rows.append({\n",
    "            \"Participant\": participant,\n",
    "            \"File\": i + 1,\n",
    "            \"Channels\": \", \".join(raw.ch_names)\n",
    "        })\n",
    "\n",
    "df_final_channels = pd.DataFrame(rows)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "display(df_final_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec98e7f7-a235-4391-a53d-bf78439bdd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_final_sd_pairs_with_attention(raw_od, attention_start=34.5, attention_end=76.5, max_pairs=None):\n",
    "    from collections import defaultdict\n",
    "    data, times = raw_od.get_data(return_times=True)\n",
    "    ch_names = raw_od.ch_names\n",
    "\n",
    "    sd_pair_map = defaultdict(dict)\n",
    "    for idx, ch_name in enumerate(ch_names):\n",
    "        parts = ch_name.split()\n",
    "        sd_id = parts[0]\n",
    "        wl = parts[1]\n",
    "        sd_pair_map[sd_id][wl] = idx\n",
    "\n",
    "    plotted = 0\n",
    "    for sd_id, wl_map in sd_pair_map.items():\n",
    "        if \"760\" in wl_map and \"850\" in wl_map:\n",
    "            idx_760 = wl_map[\"760\"]\n",
    "            idx_850 = wl_map[\"850\"]\n",
    "\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.plot(times, data[idx_760], label=f\"{sd_id} 760 nm\", color='blue')\n",
    "            plt.plot(times, data[idx_850], label=f\"{sd_id} 850 nm\", color='green')\n",
    "            plt.axvspan(attention_start, attention_end, color='red', alpha=0.2, label='Attention Period')\n",
    "            plt.title(f\"S-D Pair: {sd_id}\")\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Optical Density\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            plotted += 1\n",
    "            if max_pairs is not None and plotted >= max_pairs:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f617d82-bce0-48ac-8eff-087e7d24e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot finalized channels for each participant and file\n",
    "for participant, recordings in participant_od_final.items():\n",
    "    for i, raw in enumerate(recordings):\n",
    "        print(f\"\\n{participant} - File {i+1}\")\n",
    "        plot_final_sd_pairs_with_attention(raw, attention_start=34.5, attention_end=76.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555dd468-ed7d-4d23-ad83-fe290e752069",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from mne.io import RawArray\n",
    "from mne import create_info\n",
    "import numpy as np\n",
    "\n",
    "# === File paths\n",
    "file1_path = r\"C:\\Users\\xtwf7586\\OneDrive - University of Leeds\\New folder\\nirs-resources-main\\syntheticNIRS\\RESOD2_struct_noiselevel2.mat\"\n",
    "file2_path = r\"C:\\Users\\xtwf7586\\OneDrive - University of Leeds\\New folder\\nirs-resources-main\\syntheticNIRS\\RESOD2_struct_noiselevel2_file2.mat\"\n",
    "\n",
    "# === Load both .mat files\n",
    "mat1 = scipy.io.loadmat(file1_path)\n",
    "mat2 = scipy.io.loadmat(file2_path)\n",
    "\n",
    "print(\"File 1 keys:\", mat1.keys())\n",
    "print(\"File 2 keys:\", mat2.keys())\n",
    "\n",
    "# Get the real sampling frequency from your actual recording\n",
    "real_sfreq_file1 = participant_od_final[\"participant_1\"][0].info['sfreq']\n",
    "real_sfreq_file2 = participant_od_final[\"participant_1\"][1].info['sfreq']\n",
    "\n",
    "def build_raw_from_struct(mat, sfreq, title):\n",
    "    od_data = mat['data'].T\n",
    "    times = mat['time'].flatten()\n",
    "\n",
    "    probe = mat['probe'][0, 0]\n",
    "    link = probe['link'][0, 0]\n",
    "\n",
    "    src = link['source'].flatten()\n",
    "    det = link['detector'].flatten()\n",
    "    wl  = link['type'].flatten()\n",
    "\n",
    "    ch_names = [f\"S{src[i]}_D{det[i]} {wl[i]}\" for i in range(len(src))]\n",
    "\n",
    "    info = create_info(ch_names=ch_names, sfreq=sfreq, ch_types='fnirs_od')\n",
    "    raw = RawArray(od_data, info)\n",
    "\n",
    "    print(raw)\n",
    "    raw.plot(n_channels=10, title=title)\n",
    "    return raw\n",
    "\n",
    "\n",
    "# === Build Raw objects\n",
    "synthetic_raw_file1 = build_raw_from_struct(mat1, sfreq=real_sfreq_file1, title=\"Synthetic OD – File 1\")\n",
    "synthetic_raw_file2 = build_raw_from_struct(mat2, sfreq=real_sfreq_file2, title=\"Synthetic OD – File 2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9de96a-48cc-4b11-b7df-65771636221b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔹 Real File 1 channels:\")\n",
    "print(participant_od_final[\"participant_1\"][0].ch_names)\n",
    "\n",
    "print(\"\\n🔸 Synthetic File 1 channels:\")\n",
    "print(synthetic_raw_file1.ch_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da607564-3ce9-4af3-91f9-593834768e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_raw_file1 = synthetic_raw_file1.copy().reorder_channels(\n",
    "    participant_od_final[\"participant_1\"][0].ch_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683866fb-aae8-4054-8019-7fa1739313cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_raw_file2 = synthetic_raw_file2.copy().reorder_channels(\n",
    "    participant_od_final[\"participant_1\"][1].ch_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73f490-cf47-40a7-8f66-f8f31ea04181",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert participant_od_final[\"participant_1\"][0].ch_names == synthetic_raw_file1.ch_names\n",
    "assert participant_od_final[\"participant_1\"][1].ch_names == synthetic_raw_file2.ch_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce1b442-37d3-4297-9cf8-fc1f118ecaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Real File 1 sfreq:\", participant_od_final[\"participant_1\"][0].info['sfreq'])\n",
    "print(\"Synthetic File 1 sfreq:\", synthetic_raw_file1.info['sfreq'])\n",
    "\n",
    "print(\"Real File 2 sfreq:\", participant_od_final[\"participant_1\"][1].info['sfreq'])\n",
    "print(\"Synthetic File 2 sfreq:\", synthetic_raw_file2.info['sfreq'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38325628-90d6-4baf-beda-549316599309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert real data to RawArray\n",
    "real_raw1 = participant_od_final[\"participant_1\"][0]\n",
    "real_data1, _ = real_raw1.get_data(return_times=True)\n",
    "info1 = real_raw1.info.copy()\n",
    "real_raw_array1 = RawArray(real_data1, info1)\n",
    "\n",
    "real_raw2 = participant_od_final[\"participant_1\"][1]\n",
    "real_data2, _ = real_raw2.get_data(return_times=True)\n",
    "info2 = real_raw2.info.copy()\n",
    "real_raw_array2 = RawArray(real_data2, info2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c428eb-a9f3-4edf-9134-812c811326d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import concatenate_raws\n",
    "\n",
    "extended_file1 = concatenate_raws([real_raw_array1, synthetic_raw_file1])\n",
    "extended_file2 = concatenate_raws([real_raw_array2, synthetic_raw_file2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdd439f-8fb1-4aa1-8bc1-283d392739bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_od_final[\"participant_1\"][0] = extended_file1\n",
    "participant_od_final[\"participant_1\"][1] = extended_file2\n",
    "print(\"Extended File 1 duration (sec):\", participant_od_final[\"participant_1\"][0].times[-1])\n",
    "print(\"Extended File 2 duration (sec):\", participant_od_final[\"participant_1\"][1].times[-1])\n",
    "print(\"File 1: n_times =\", participant_od_final[\"participant_1\"][0].n_times)\n",
    "print(\"sfreq =\", participant_od_final[\"participant_1\"][0].info['sfreq'])\n",
    "print(\"duration (computed) =\", participant_od_final[\"participant_1\"][0].n_times / participant_od_final[\"participant_1\"][0].info['sfreq'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edee4f9-7dbb-4078-87ba-d779922902bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_od_final[\"participant_1\"][0].save(\"participant1_file1_extended_raw.fif\", overwrite=True)\n",
    "participant_od_final[\"participant_1\"][1].save(\"participant1_file2_extended_raw.fif\", overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4b948-1cfb-4134-91ee-c21250acd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Extended File 1\n",
    "participant_od_final[\"participant_1\"][0].plot(\n",
    "    n_channels=10,\n",
    "    title=\"Extended File 1 – Real + Synthetic\",\n",
    "    duration=20,\n",
    "    start=0\n",
    ")\n",
    "\n",
    "# Plot Extended File 2\n",
    "participant_od_final[\"participant_1\"][1].plot(\n",
    "    n_channels=10,\n",
    "    title=\"Extended File 2 – Real + Synthetic\",\n",
    "    duration=20,\n",
    "    start=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca97f4-8836-4ef2-a51f-2600e9f864b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def plot_extended_sd_pairs(raw_od, attention_start=34.5, attention_end=76.5, max_pairs=None):\n",
    "    data, times = raw_od.get_data(return_times=True)\n",
    "    ch_names = raw_od.ch_names\n",
    "\n",
    "    sd_pair_map = defaultdict(dict)\n",
    "    for idx, ch_name in enumerate(ch_names):\n",
    "        parts = ch_name.split()\n",
    "        sd_id = parts[0]  # \"S3_D4\"\n",
    "        wl = parts[1]     # \"760\" or \"850\"\n",
    "        sd_pair_map[sd_id][wl] = idx\n",
    "\n",
    "    plotted = 0\n",
    "    for sd_id, wl_map in sd_pair_map.items():\n",
    "        if \"760\" in wl_map and \"850\" in wl_map:\n",
    "            idx_760 = wl_map[\"760\"]\n",
    "            idx_850 = wl_map[\"850\"]\n",
    "\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.plot(times, data[idx_760], label=f\"{sd_id} 760 nm\", color='blue')\n",
    "            plt.plot(times, data[idx_850], label=f\"{sd_id} 850 nm\", color='green')\n",
    "\n",
    "            # Highlight attention period\n",
    "            plt.axvspan(attention_start, attention_end, color='red', alpha=0.2, label='Attention')\n",
    "\n",
    "            # Highlight synthetic/resting period (after attention ends)\n",
    "            if times[-1] > attention_end:\n",
    "                plt.axvspan(attention_end, times[-1], color='gray', alpha=0.1, label='Synthetic Rest')\n",
    "\n",
    "            plt.title(f\"S-D Pair: {sd_id}\")\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Optical Density\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            plotted += 1\n",
    "            if max_pairs is not None and plotted >= max_pairs:\n",
    "                break\n",
    "# Plot extended File 1\n",
    "plot_extended_sd_pairs(participant_od_final[\"participant_1\"][0], attention_start=34.5, attention_end=52.21)\n",
    "\n",
    "# Plot extended File 2\n",
    "plot_extended_sd_pairs(participant_od_final[\"participant_1\"][1], attention_start=34.5, attention_end=47.814)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ecbe95-2dd5-4bff-aa93-4dbb52b5b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.preprocessing.nirs import beer_lambert_law\n",
    "for participant, recordings in participant_od_final.items():\n",
    "    hb_list = []\n",
    "\n",
    "    for i, raw_od in enumerate(recordings):\n",
    "        if participant == \"participant_1\" and i in [0, 1]:\n",
    "            raw_od = participant_od_final[participant][i]  # already extended\n",
    "\n",
    "        # ✅ Step 1: Convert OD to Hb\n",
    "        raw_hb = beer_lambert_law(raw_od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8431c0-7db4-44ff-ac00-496db4727d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def plot_sd_pairs_hbo_hbr(raw_hb, attention_start=34.5, attention_end=76.5, max_pairs=None):\n",
    "    data, times = raw_hb.get_data(return_times=True)\n",
    "    ch_names = raw_hb.ch_names\n",
    "\n",
    "    # Group HbO/HbR indices by source-detector pair\n",
    "    sd_pair_map = defaultdict(dict)\n",
    "    for idx, name in enumerate(ch_names):\n",
    "        parts = name.split()\n",
    "        sd_id = parts[0]  # e.g., \"S3_D4\"\n",
    "        chrom = parts[1]  # \"hbo\" or \"hbr\"\n",
    "        sd_pair_map[sd_id][chrom] = idx\n",
    "\n",
    "    plotted = 0\n",
    "    for sd_id, chrom_map in sd_pair_map.items():\n",
    "        if \"hbo\" in chrom_map and \"hbr\" in chrom_map:\n",
    "            idx_hbo = chrom_map[\"hbo\"]\n",
    "            idx_hbr = chrom_map[\"hbr\"]\n",
    "\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.plot(times, data[idx_hbo], label=f\"{sd_id} HbO\", color='red')\n",
    "            plt.plot(times, data[idx_hbr], label=f\"{sd_id} HbR\", color='blue')\n",
    "            plt.axvspan(attention_start, attention_end, color='pink', alpha=0.2, label='Attention Period')\n",
    "            plt.title(f\"Hemoglobin: {sd_id}\")\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"µmol/L\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            plotted += 1\n",
    "            if max_pairs is not None and plotted >= max_pairs:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100e18e-c06c-4078-b115-5754666e1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, raw_od in enumerate(participant_od_final[\"participant_1\"]):\n",
    "    print(f\"Participant 1 – File {i+1}\")\n",
    "    raw_hb = beer_lambert_law(raw_od)\n",
    "    plot_sd_pairs_hbo_hbr(raw_hb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a0b06-d947-4e21-8350-7cd55bd903ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_psd_comparison(raw_hb, filtered_data=None, title_prefix=\"\"):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    raw_hb.plot_psd(fmax=1.0, average=True, show=False)\n",
    "    plt.title(f\"{title_prefix} - PSD Before Filtering\")\n",
    "\n",
    "    if filtered_data is not None:\n",
    "        from mne.io import RawArray\n",
    "        import numpy as np\n",
    "        info = raw_hb.info.copy()\n",
    "        raw_filtered = RawArray(filtered_data, info)\n",
    "        raw_filtered.plot_psd(fmax=1.0, average=True, show=False)\n",
    "        plt.title(f\"{title_prefix} - PSD After Filtering\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c31bb6-a7bd-4f2b-a959-fde65474cbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def butter_bandpass_filter(data, sfreq, lowcut=0.001, highcut=0.2, order=3):\n",
    "    nyq = 0.5 * sfreq\n",
    "    b, a = butter(order, [lowcut / nyq, highcut / nyq], btype='band')\n",
    "    return filtfilt(b, a, data, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2537cf-ac1e-42a2-8f09-4d8692f0acc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_hb_final = {}\n",
    "\n",
    "for participant, recordings in participant_od_final.items():\n",
    "    hb_list = []\n",
    "\n",
    "    for i, raw_od in enumerate(recordings):\n",
    "        # 1. Convert to hemoglobin\n",
    "        raw_hb = beer_lambert_law(raw_od)\n",
    "\n",
    "        # 2. Filter\n",
    "        sfreq = raw_hb.info['sfreq']\n",
    "        filtered_data = butter_bandpass_filter(raw_hb.get_data(), sfreq)\n",
    "\n",
    "        # 3. Overwrite with filtered data\n",
    "        raw_hb._data = filtered_data\n",
    "\n",
    "        # 4. (Optional) Downsample to match Tufts\n",
    "        raw_hb.resample(5.2, npad=\"auto\")\n",
    "\n",
    "        hb_list.append(raw_hb)\n",
    "\n",
    "    participant_hb_final[participant] = hb_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20490e02-0211-476f-9b1a-085d069f13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant, files in participant_hb_final.items():\n",
    "    print(f\"\\n=== {participant} ===\")\n",
    "    for i, raw in enumerate(files):\n",
    "        sfreq = raw.info['sfreq']\n",
    "        duration = raw.times[-1]\n",
    "        print(f\"File {i+1}: sfreq = {sfreq:.2f} Hz | Duration = {duration:.2f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f349368-5737-44b1-a088-2e10e037d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_psd_comparison(\n",
    "    raw_hb,\n",
    "    filtered_data=filtered_data,\n",
    "    title_prefix=f\"{participant} File {i+1}\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2741deb-5737-4890-8c91-c3ac59982b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"File being processed:\", participant, \"File\", i+1)\n",
    "print(\"Duration (s):\", raw_od.times[-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a960639-cf9a-4830-bb76-93180bc743f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.preprocessing.nirs import beer_lambert_law\n",
    "\n",
    "for i in range(4):  # Files 0 to 3 (i+1 = 1 to 4)\n",
    "    print(f\"\\n🔍 Participant 1 – File {i+1}\")\n",
    "    \n",
    "    raw_od = participant_od_final[\"participant_1\"][i]\n",
    "    raw_hb = beer_lambert_law(raw_od)\n",
    "\n",
    "    sfreq = raw_hb.info['sfreq']\n",
    "    raw_data = raw_hb.get_data()\n",
    "    filtered_data = butter_bandpass_filter(raw_data, sfreq)\n",
    "\n",
    "    plot_psd_comparison(raw_hb, filtered_data, title_prefix=f\"Participant 1 File {i+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a104f27-50e5-408e-93d5-a183c51bfb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sliding_windows(raw_data, window_size=150, step_size=3):\n",
    "\n",
    "    windows = []\n",
    "    n_channels, n_times = raw_data.shape\n",
    "    for start in range(0, n_times - window_size + 1, step_size):\n",
    "        window = raw_data[:, start:start + window_size].T  # shape (150, n_channels)\n",
    "        windows.append(window)\n",
    "    return np.stack(windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0ec300-6252-469a-95de-389e70431161",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_windows = {}\n",
    "for participant, recordings in participant_hb_final.items():\n",
    "    participant_windows = []\n",
    "    for i, raw_hb in enumerate(recordings):\n",
    "        raw_data = raw_hb.get_data()\n",
    "        windows = extract_sliding_windows(raw_data)  # shape: (n_windows, 150, n_channels)\n",
    "        participant_windows.append(windows)\n",
    "    all_windows[participant] = participant_windows\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29777382-4b48-4abe-8466-3852743cae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant, windows_list in all_windows.items():\n",
    "    print(f\"\\n=== {participant} ===\")\n",
    "    for i, windows in enumerate(windows_list):\n",
    "        print(f\"File {i+1}: shape = {windows.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce9c59-fd98-4ba0-a9fa-2d8b2df0775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_windows(recording_durations, window_size_sec=30, stride_sec=0.6):\n",
    "    labels_by_participant = {}\n",
    "\n",
    "    for participant, file_durations in recording_durations.items():\n",
    "        labels_by_file = []\n",
    "\n",
    "        for i, duration in enumerate(file_durations):\n",
    "            n_windows = int((duration - window_size_sec) / stride_sec) + 1\n",
    "            labels = []\n",
    "\n",
    "            for w in range(n_windows):\n",
    "                window_end = w * stride_sec + window_size_sec  # Tufts-style: use endpoint only\n",
    "\n",
    "                # Define attention windows\n",
    "                if participant == \"participant_1\" and i == 0:\n",
    "                    attention_start, attention_end = 34.5, 52.22\n",
    "                elif participant == \"participant_1\" and i == 1:\n",
    "                    attention_start, attention_end = 34.5, 47.81\n",
    "                else:\n",
    "                    attention_start, attention_end = 34.5, 76.5\n",
    "\n",
    "                # Label based on whether window END falls in attention\n",
    "                if attention_start <= window_end <= attention_end:\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "\n",
    "            labels_by_file.append(labels)\n",
    "        labels_by_participant[participant] = labels_by_file\n",
    "\n",
    "    return labels_by_participant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea683cd9-c005-406f-b595-acbcf10ee034",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_durations = {\n",
    "    \"participant_1\": [76.35, 76.35, 119.23, 92.12],\n",
    "    \"participant_2\": [129.62, 91.73, 96.92, 80.38],\n",
    "    \"participant_3\": [86.73, 97.50, 87.88, 92.69]\n",
    "}\n",
    "\n",
    "labels_all = label_windows(recording_durations)  # \n",
    "\n",
    "participant = \"participant_1\"\n",
    "file_idx = 0\n",
    "windows = all_windows[participant][file_idx]\n",
    "labels = labels_all[participant][file_idx]  # \n",
    "\n",
    "# Plot the last 5 windows\n",
    "for idx in range(len(labels) - 5, len(labels)):\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(windows[idx][:, 0], color='purple')  # channel 0 (HbO or HbR)\n",
    "    plt.title(f\"Window {idx} – Label: {labels[idx]}\")\n",
    "    plt.xlabel(\"Time points (at 5.2 Hz)\")\n",
    "    plt.ylabel(\"Signal\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Print end times and labels\n",
    "for idx in range(len(labels)):\n",
    "    end_time = idx * 0.6 + 30\n",
    "    print(f\"Window {idx} | Ends at ~{end_time:.1f}s | Label: {labels[idx]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b8b6de-5d7a-4632-9d3d-c019727f9328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_8_channels(raw, selected_pairs):\n",
    "    selected_chs = []\n",
    "    for ch_name in raw.ch_names:\n",
    "        for pair in selected_pairs:\n",
    "            if pair in ch_name and ('hbo' in ch_name or 'hbr' in ch_name):\n",
    "                selected_chs.append(ch_name)\n",
    "    return raw.copy().pick_channels(selected_chs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c70d0-d3f0-41ba-b126-da60483ae7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pairs = ['S3_D3', 'S4_D4', 'S6_D6', 'S8_D6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22959562-3e7f-47d1-b251-157dedebd821",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_hb_selected = {}\n",
    "\n",
    "for participant, recordings in participant_hb_final.items():\n",
    "    selected_list = []\n",
    "    for raw in recordings:\n",
    "        selected_raw = select_8_channels(raw, selected_pairs)\n",
    "        selected_list.append(selected_raw)\n",
    "    participant_hb_selected[participant] = selected_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ac3ed-2d93-49d1-bcf9-42556585f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant, files in participant_hb_selected.items():\n",
    "    print(f\"\\n{participant}\")\n",
    "    for i, raw in enumerate(files):\n",
    "        print(f\"File {i+1}: {len(raw.ch_names)} channels → {raw.ch_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0331ab1-5ab7-4ffc-9b03-328b517144c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sliding_windows(raw_data, window_size=150, step_size=3):\n",
    "    windows = []\n",
    "    n_channels, n_times = raw_data.shape\n",
    "    for start in range(0, n_times - window_size + 1, step_size):\n",
    "        window = raw_data[:, start:start + window_size].T  # (150, 8)\n",
    "        windows.append(window)\n",
    "    return np.stack(windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fb9a7b-9496-4b12-9b15-86879b52f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_windows = {}\n",
    "\n",
    "for participant, recordings in participant_hb_selected.items():\n",
    "    participant_windows = []\n",
    "    for i, raw_hb in enumerate(recordings):\n",
    "        raw_data = raw_hb.get_data()\n",
    "        windows = extract_sliding_windows(raw_data)  # shape: (n_windows, 150, 8)\n",
    "        participant_windows.append(windows)\n",
    "    all_windows[participant] = participant_windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72aab56-3dbd-4483-a4a9-32cf91e2f1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all = label_windows(recording_durations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e92ce-8d5d-4062-a741-e06c4f3469b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant in all_windows:\n",
    "    print(f\"\\n{participant}\")\n",
    "    for i in range(4):\n",
    "        print(f\"File {i+1}: {all_windows[participant][i].shape[0]} windows | {len(labels_all[participant][i])} labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48860eb9-3add-4f43-b854-6705e28a5afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for participant in all_windows:\n",
    "    for i in range(len(all_windows[participant])):\n",
    "        windows = all_windows[participant][i]\n",
    "        labels = labels_all[participant][i]\n",
    "\n",
    "        # Trim to match\n",
    "        min_len = min(len(windows), len(labels))\n",
    "        windows = windows[:min_len]\n",
    "        labels = labels[:min_len]\n",
    "\n",
    "        X_list.append(windows)\n",
    "        y_list.append(labels)\n",
    "\n",
    "# Step 2: Convert to arrays\n",
    "X = np.vstack(X_list)  # Shape: (N, 150, 8)\n",
    "y = np.hstack(y_list)  # Shape: (N,)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Label counts:\", np.bincount(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b8596-f696-4dd4-b58a-5ebd8464318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.transpose(X, (0, 2, 1)).astype(np.float32)\n",
    "X_test = TSTensor(X_test)\n",
    "print(X_test.shape)  # should now be (1285, 8, 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212e50b4-bda1-40dd-a55f-831e20f6aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "# Patch to avoid PosixPath error on Windows\n",
    "if sys.platform == \"win32\":\n",
    "    pathlib.PosixPath = pathlib.WindowsPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad01c4-b451-4814-9e16-7bc82f41a2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = r\"C:\\Users\\xtwf7586\\OneDrive - University of Leeds\\fnirs\\AuditoryRecording13032025\\models\\models\\LSTM_Tufts_Ccclean.pkl\"\n",
    "print(\"Exists?\", os.path.exists(p))  # should be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951b636a-4129-49d2-9e87-e267937933e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.all import *\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "learn = load_learner(p)\n",
    "print(\"✅ Loaded:\", learn.model.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af12e679-7c57-4831-beac-70866f2d087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.all import *\n",
    "import numpy as np\n",
    "from tsai.data.core import TSTensor\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# 3) Get predictions — handle variable return lengths across tsai versions\n",
    "res = learn.get_X_preds(X_test, y=y, bs=128)\n",
    "# res can be (probs, targs) or (probs, targs, decoded) or (probs, targs, decoded, losses)\n",
    "probs = res[0]\n",
    "targs = res[1] if len(res) > 1 else None\n",
    "\n",
    "# 4) Metrics (use your y directly if targs is None)\n",
    "preds_class = probs.argmax(1).cpu().numpy()\n",
    "true_y = y if targs is None else targs.cpu().numpy()\n",
    "\n",
    "print(\" Accuracy:\", accuracy_score(true_y, preds_class))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_y, preds_class))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_y, preds_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd8950-e0f2-4694-a7ff-9cbc1cce7849",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_y, preds_class)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Class 0', 'Class 1'],\n",
    "            yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49de9f91-f9dc-46a8-b889-d54d2bb36624",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(X_test), X_test.shape, X_test.dtype)   # should show TSTensor, (N, 8, 150), float32\n",
    "print(len(y), \"labels\")                           # should equal N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac710c7a-b0d6-4dd0-ad9a-e64be8aa5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.all import *\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Recompute preds safely\n",
    "res = learn.get_X_preds(X_test, y=y, bs=128)   # returns (probs, targs, ...) across versions\n",
    "probs = res[0]\n",
    "targs = res[1] if len(res) > 1 else None\n",
    "\n",
    "# Use your provided labels as ground truth\n",
    "true_y = y\n",
    "\n",
    "# Class-1 probabilities + argmax preds\n",
    "p1 = probs[:, 1].cpu().numpy()\n",
    "preds_class = probs.argmax(1).cpu().numpy()\n",
    "\n",
    "print(\"Pred class counts:\", {int(k): int(v) for k,v in zip(*np.unique(preds_class, return_counts=True))})\n",
    "print(\"p(class=1) mean/min/max:\", float(p1.mean()), float(p1.min()), float(p1.max()))\n",
    "\n",
    "print(\"\\nAccuracy@0.5:\", accuracy_score(true_y, preds_class))\n",
    "print(confusion_matrix(true_y, preds_class))\n",
    "print(classification_report(true_y, preds_class, digits=3))\n",
    "\n",
    "# ROC AUC + best threshold via Youden's J\n",
    "auc = roc_auc_score(true_y, p1)\n",
    "fpr, tpr, thr = roc_curve(true_y, p1)\n",
    "best_thr = thr[(tpr - fpr).argmax()]\n",
    "preds_thr = (p1 >= best_thr).astype(int)\n",
    "\n",
    "print(\"\\nROC AUC:\", auc, \"| Best threshold:\", best_thr)\n",
    "print(\"Accuracy@best_thr:\", accuracy_score(true_y, preds_thr))\n",
    "print(confusion_matrix(true_y, preds_thr))\n",
    "print(classification_report(true_y, preds_thr, digits=3))\n",
    "\n",
    "# Check label polarity hypothesis\n",
    "print(\"\\nAccuracy if labels inverted:\", accuracy_score(1 - true_y, preds_class))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72afb246-e464-47a5-881a-ac47966bb187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tsai, fastai\n",
    "print(\"tsai:\", tsai.__version__)\n",
    "print(\"fastai:\", fastai.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f3a319-0f13-4a23-bd68-62a027051ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train/val split (random)\n",
    "X_cf = np.transpose(X, (0, 2, 1)).astype(np.float32)   # (N, 8, 150)\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(y)),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "splits = (list(train_idx), list(val_idx))\n",
    "\n",
    "# Slice from X_cf instead of X\n",
    "X_train, X_val = X_cf[splits[0]], X_cf[splits[1]]\n",
    "y_train, y_val = y[splits[0]], y[splits[1]]\n",
    "\n",
    "print(\"Train data shape:\", X_train.shape)   # (1028, 8, 150)\n",
    "print(\"Validation data shape:\", X_val.shape) # (257, 8, 150)\n",
    "print(\"Train label counts:\", np.bincount(y_train))\n",
    "print(\"Validation label counts:\", np.bincount(y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f37a311-d213-4dbb-9b14-201ca62da418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.all import *\n",
    "from fastai.callback.all import SaveModelCallback\n",
    "\n",
    "# Define transforms\n",
    "tfms = [None, [Categorize()]]\n",
    "batch_tfms = TSStandardize(by_sample=True)\n",
    "\n",
    "# Create datasets with splits\n",
    "dsets = TSDatasets(X_cf, y, tfms=tfms, splits=splits, inplace=True)\n",
    "\n",
    "\n",
    "# Create DataLoaders\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=[TSStandardize()], num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbd46a5-ff9c-4d7a-bd61-1a6b5f53c34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callback.all import SaveModelCallback\n",
    "\n",
    "mv_clf = TSClassifier(\n",
    "    X_cf, y, splits=splits,\n",
    "    arch=LSTM, arch_config={'n_layers': 3, 'bidirectional': True},\n",
    "    tfms=tfms, batch_tfms=batch_tfms,\n",
    "    metrics=accuracy,\n",
    "    path='models',\n",
    "    cbs=ShowGraph()\n",
    ")\n",
    "\n",
    "# Train it\n",
    "mv_clf.fit_one_cycle(20, 1e-3)  # 1e-3 is safer for LSTM, but you can match Tufts exactly\n",
    "\n",
    "# Export the trained model\n",
    "mv_clf.save('own_final')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a96c8-b231-406c-91ff-efcd11283da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Validation predictions\n",
    "logits_val, preds_val, targs_val = mv_clf.get_preds(with_input=False, with_decoded=True)\n",
    "\n",
    "val_acc = accuracy_score(targs_val, preds_val)\n",
    "print(f\"Validation Accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a6e3e-ff12-4d07-8720-20bc1214c2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mv_clf.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a45ac47-ea06-4a61-9416-ad2176b9a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"path:\", mv_clf.path)        # usually 'models'\n",
    "print(\"model_dir:\", mv_clf.model_dir)  # usually 'models'\n",
    "# Full path is path/model_dir/<name>.pth  e.g. models/models/own_final.pth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fd9802-e3d8-45a4-b938-ff99c2ce24f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training predictions\n",
    "logits_train, preds_train, targs_train = mv_clf.get_preds(ds_idx=0, with_input=False, with_decoded=True)\n",
    "\n",
    "train_acc = accuracy_score(targs_train, preds_train)\n",
    "print(f\" Training Accuracy: {train_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6417c8-64f3-45ee-ac4c-f71f05779a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(targs_val, preds_val)\n",
    "\n",
    "# Plot confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Rest\", \"Attention\"])\n",
    "disp.plot(cmap='Blues', xticks_rotation=45)\n",
    "\n",
    "plt.title(\"Confusion Matrix – Validation Set\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c805424c-f28f-433a-a799-f14f5360faee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.all import *\n",
    "\n",
    ":\n",
    "model = create_model(LSTM, c_in=8, c_out=2, seq_len=150, arch_config={'n_layers': 3, 'bidirectional': True})\n",
    "\n",
    "# Step 2: Create dummy dataloaders (for export only)\n",
    "def get_dummy_dl(seq_len=150, n_vars=8, n_classes=2):\n",
    "    X_dummy = np.random.randn(2, 8, 150).astype(np.float32)\n",
    "    y_dummy = np.array([0, 1])\n",
    "    tfms = [None, [Categorize()]]\n",
    "    dsets = TSDatasets(X_dummy, y_dummy, tfms=tfms)\n",
    "    return TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=2)\n",
    "\n",
    "dls = get_dummy_dl()\n",
    "\n",
    "# \n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    metrics=accuracy,\n",
    "    path='models/models',   # \n",
    "    model_dir='.'           # \n",
    ")\n",
    "\n",
    "# t\n",
    "learn.load('own_final')  #\n",
    "learn.export('LSTM_finalL_clean_export.pkl')  # \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d27ce0-da51-435a-9ef3-bdbda1da50f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "export_path = Path(learn.path) / learn.model_dir / \"LSTM_finalL_clean_export.pkl\"\n",
    "print(\" Model exported to:\", export_path)\n",
    "print(\"File exists?\", export_path.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c5f243-7cd8-450f-ab85-81ca35748be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
