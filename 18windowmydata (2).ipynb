{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d73613c-066d-465b-890e-2b50dfbfded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1accessing importing the files\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc327534-7070-47ab-97e5-c5cdb88180ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2accessing the files.\n",
    "root_path = r\"C:\\Users\\xtwf7586\\OneDrive - University of Leeds\\fnirs\\AuditoryRecording13032025\"\n",
    "all_folders = [f\"2025-03-13_{i:03d}\" for i in range(1, 14) if i != 2]\n",
    "print(\"Folders to be loaded:\")\n",
    "print(all_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40171073-1bff-4b7d-ba10-ff47aa6ac2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3accessing all the files of the participants and getting their duration\n",
    "participant_data = {f\"participant_{i+1}\": [] for i in range(3)}\n",
    "\n",
    "for idx, folder_name in enumerate(all_folders):\n",
    "    folder_path = os.path.join(root_path, folder_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"Folder not found: {folder_path}\")\n",
    "        continue\n",
    "    snirf_files = [f for f in os.listdir(folder_path) if f.endswith(\".snirf\")]\n",
    "    if not snirf_files:\n",
    "        print(f\"No .snirf file found in {folder_path}\")\n",
    "        continue\n",
    "    snirf_path = os.path.join(folder_path, snirf_files[0])\n",
    "    print(f\"Loading {snirf_path}\")\n",
    "    raw = mne.io.read_raw_snirf(snirf_path, preload=True)\n",
    "    participant_idx = idx // 4\n",
    "    participant_key = f\"participant_{participant_idx + 1}\"\n",
    "    participant_data[participant_key].append(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2303a0f-9ea8-4c97-9673-ebb025579600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all 4 files from all 3 participants, getting their sampling frequency and durations.\n",
    "for key, files in participant_data.items():\n",
    "    print(f\"{key}: {len(files)} SNIRF files loaded\")\n",
    "\n",
    "for participant, raws in participant_data.items():\n",
    "    print(f\"\\n=== {participant} ===\")\n",
    "    for i, raw in enumerate(raws):\n",
    "        print(f\"File {i+1}: Channels={len(raw.ch_names)}, Duration={raw.times[-1]:.2f}s, Sampling Frequency={raw.info['sfreq']:.2f} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cad5ac-88d9-4525-85e8-9a9bedc3c27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10\n",
    "from collections import defaultdict\n",
    "from mne.preprocessing.nirs import optical_density\n",
    "\n",
    "cv_threshold = 7.5  # from the automated named study in percent\n",
    "participant_raw_cv_filtered = {}\n",
    "participant_raw_cv_rejected = {}  # <-- new dict to store bad channels\n",
    "\n",
    "for participant, raws in participant_data.items():\n",
    "    participant_raw_cv_filtered[participant] = []\n",
    "    participant_raw_cv_rejected[participant] = []\n",
    "\n",
    "    for i, raw in enumerate(raws):\n",
    "        data = raw.get_data()\n",
    "        mean = np.mean(data, axis=1)\n",
    "        std = np.std(data, axis=1)\n",
    "        cv = 100 * std / mean\n",
    "\n",
    "        # Group by S-D pair (ignoring wavelength)\n",
    "        pair_map = defaultdict(list)\n",
    "        for idx, ch_name in enumerate(raw.ch_names):\n",
    "            pair_id = \" \".join(ch_name.split()[:-1])  # e.g., \"S1_D1\"\n",
    "            pair_map[pair_id].append(idx)\n",
    "\n",
    "        good_idx, bad_idx = [], []\n",
    "        for pair_id, indices in pair_map.items():\n",
    "            if len(indices) == 2:\n",
    "                if all(cv[idx] < cv_threshold for idx in indices):\n",
    "                    good_idx.extend(indices)\n",
    "                else:\n",
    "                    bad_idx.extend(indices)\n",
    "\n",
    "        # Store filtered (good) and rejected (bad) Raw objects\n",
    "        good_chs = [raw.ch_names[idx] for idx in good_idx]\n",
    "        bad_chs = [raw.ch_names[idx] for idx in bad_idx]\n",
    "\n",
    "        raw_good = raw.copy().pick(good_chs)\n",
    "        raw_bad = raw.copy().pick(bad_chs)\n",
    "\n",
    "        participant_raw_cv_filtered[participant].append(raw_good)\n",
    "        participant_raw_cv_rejected[participant].append(raw_bad)\n",
    "\n",
    "        print(f\"{participant} File {i+1}: Kept {len(good_chs)} | Dropped {len(bad_chs)} channels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cda1b3-6d6b-4add-9658-ab0293e66b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11\n",
    "participant_od_good = {}\n",
    "participant_od_bad = {}\n",
    "\n",
    "for participant in participant_raw_cv_filtered:\n",
    "    participant_od_good[participant] = []\n",
    "    participant_od_bad[participant] = []\n",
    "\n",
    "    for i in range(len(participant_raw_cv_filtered[participant])):\n",
    "        raw_good = participant_raw_cv_filtered[participant][i]\n",
    "        raw_bad = participant_raw_cv_rejected[participant][i]\n",
    "\n",
    "        od_good = optical_density(raw_good)\n",
    "        od_bad = optical_density(raw_bad)\n",
    "\n",
    "        participant_od_good[participant].append(od_good)\n",
    "        participant_od_bad[participant].append(od_bad)\n",
    "\n",
    "        print(f\"Plotting GOOD: {participant} - File {i+1}\")\n",
    "        od_good.plot(title=f\"{participant} - File {i+1} (GOOD Channels)\")\n",
    "    \n",
    "\n",
    "        print(f\"Plotting BAD: {participant} - File {i+1}\")\n",
    "        od_bad.plot(title=f\"{participant} - File {i+1} (BAD Channels)\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b053d-0277-4ac3-bba9-c7273662897b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant, od_list in participant_od_good.items():\n",
    "    print(f\"\\n=== {participant} ===\")\n",
    "    for i, raw_od in enumerate(od_list):\n",
    "        n_channels = len(raw_od.ch_names)\n",
    "        print(f\"File {i+1}: {n_channels} OD channels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376b1d45-cc5c-4311-b362-dfe39fca9cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def plot_sd_pairs_with_task_overlay(raw_od, attention_start=34.5, attention_end=76.5, max_pairs=None):\n",
    "    \"\"\"\n",
    "    Plot optical density signals for S-D pairs with both 760 and 850 nm wavelengths.\n",
    "    Highlights the task window for easy visual inspection.\n",
    "\n",
    "    Parameters:\n",
    "    - raw_od: MNE Raw object (optical density)\n",
    "    - attention_start: start time of task/stimulus (in seconds)\n",
    "    - attention_end: end time of task/stimulus (in seconds)\n",
    "    - max_pairs: maximum number of S-D pairs to plot (optional)\n",
    "    \"\"\"\n",
    "    data, times = raw_od.get_data(return_times=True)\n",
    "    ch_names = raw_od.ch_names\n",
    "\n",
    "    # Group channel indices by S-D pair ID (e.g., \"S3_D4\")\n",
    "    sd_pair_map = defaultdict(dict)\n",
    "    for idx, ch_name in enumerate(ch_names):\n",
    "        parts = ch_name.split()\n",
    "        sd_id = parts[0]  # e.g., \"S3_D4\"\n",
    "        wl = parts[1]     # e.g., \"760\" or \"850\"\n",
    "        sd_pair_map[sd_id][wl] = idx\n",
    "\n",
    "    plotted = 0\n",
    "    for sd_id, wl_map in sd_pair_map.items():\n",
    "        if \"760\" in wl_map and \"850\" in wl_map:\n",
    "            idx_760 = wl_map[\"760\"]\n",
    "            idx_850 = wl_map[\"850\"]\n",
    "\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.plot(times, data[idx_760], label=f\"{sd_id} 760 nm\", color='blue')\n",
    "            plt.plot(times, data[idx_850], label=f\"{sd_id} 850 nm\", color='green')\n",
    "            plt.axvspan(attention_start, attention_end, color='red', alpha=0.2, label='Attention Period')\n",
    "            plt.title(f\"S-D Pair: {sd_id}\")\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Optical Density\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "             # üßπ Closes the figure to prevent buildup\n",
    "\n",
    "\n",
    "            plotted += 1\n",
    "            if max_pairs is not None and plotted >= max_pairs:\n",
    "                break\n",
    "for participant in participant_od_good:\n",
    "    for i in range(len(participant_od_good[participant])):\n",
    "        print(f\"\\nInspecting GOOD channels: {participant} - File {i+1}\")\n",
    "        plot_sd_pairs_with_task_overlay(\n",
    "            participant_od_good[participant][i],\n",
    "            attention_start=34.5,\n",
    "            attention_end=76.5,\n",
    "       \n",
    "        )\n",
    "\n",
    "        print(f\"\\nInspecting BAD channels: {participant} - File {i+1}\")\n",
    "        plot_sd_pairs_with_task_overlay(\n",
    "            participant_od_bad[participant][i],\n",
    "            attention_start=34.5,\n",
    "            attention_end=76.5,\n",
    "\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a73e90-d70f-4c02-bd12-cb590d686d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# Final hand-picked S-D pairs per participant\n",
    "final_channels = {\n",
    "    \"participant_1\": [\n",
    "        \"S3_D3\", \"S3_D4\", \"S4_D4\", \"S5_D3\", \"S6_D4\", \"S6_D5\", \"S6_D6\", \"S7_D5\", \"S8_D6\"\n",
    "    ],\n",
    "    \"participant_2\": [\n",
    "        \"S2_D1\", \"S3_D3\", \"S3_D4\", \"S4_D4\", \"S5_D3\", \"S6_D4\", \"S6_D5\", \"S6_D6\", \"S7_D5\", \"S8_D6\"\n",
    "    ],\n",
    "    \"participant_3\": [\n",
    "        \"S1_D1\", \"S2_D1\", \"S3_D3\", \"S3_D4\", \"S4_D2\", \"S4_D4\", \"S5_D3\", \"S6_D4\", \"S6_D5\", \"S6_D6\",\n",
    "        \"S7_D5\", \"S7_D7\", \"S8_D6\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "# Prepare new dictionary\n",
    "participant_od_final = {}\n",
    "\n",
    "# Loop through participants\n",
    "for participant in participant_od_good.keys():\n",
    "    final_list = []\n",
    "    for i in range(len(participant_od_good[participant])):\n",
    "\n",
    "        # Combine good and bad channels\n",
    "        combined_raw = participant_od_good[participant][i].copy().add_channels(\n",
    "            [participant_od_bad[participant][i].copy()],\n",
    "            force_update_info=True\n",
    "        )\n",
    "\n",
    "        # Map S-D IDs to their channel indices\n",
    "        ch_names = combined_raw.ch_names\n",
    "        channel_map = defaultdict(list)\n",
    "        for idx, name in enumerate(ch_names):\n",
    "            parts = name.split()\n",
    "            sd_id = parts[0]  # e.g., \"S3_D4\"\n",
    "            wl = parts[1]     # e.g., \"760\"\n",
    "            channel_map[sd_id].append(idx)\n",
    "\n",
    "        # Collect indices of final desired channels\n",
    "        desired_channels = final_channels[participant]\n",
    "                # Enforce correct ordering of S-D pairs\n",
    "        indices_to_keep = []\n",
    "        for sd_pair in final_channels[participant]:\n",
    "            if sd_pair in channel_map:\n",
    "                # Always add 760 first, then 850 for consistency\n",
    "                wl_sorted = sorted(channel_map[sd_pair], key=lambda idx: combined_raw.ch_names[idx].split()[1])\n",
    "\n",
    "                indices_to_keep.extend(wl_sorted)\n",
    "\n",
    "\n",
    "        # Pick final channels\n",
    "        raw_selected = combined_raw.copy().pick(indices_to_keep)\n",
    "        final_list.append(raw_selected)\n",
    "\n",
    "    participant_od_final[participant] = final_list\n",
    "\n",
    "# üßæ Display in readable format using pandas\n",
    "rows = []\n",
    "for participant, recordings in participant_od_final.items():\n",
    "    for i, raw in enumerate(recordings):\n",
    "        rows.append({\n",
    "            \"Participant\": participant,\n",
    "            \"File\": i + 1,\n",
    "            \"Channels\": \", \".join(raw.ch_names)\n",
    "        })\n",
    "\n",
    "df_final_channels = pd.DataFrame(rows)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "display(df_final_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e5df2-0cdf-4f08-951f-c8248426a79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "from mne.io import RawArray\n",
    "from mne import create_info\n",
    "import numpy as np\n",
    "\n",
    "# === File paths\n",
    "file1_path = r\"C:\\Users\\xtwf7586\\OneDrive - University of Leeds\\New folder\\nirs-resources-main\\syntheticNIRS\\RESOD2_struct_noiselevel2.mat\"\n",
    "file2_path = r\"C:\\Users\\xtwf7586\\OneDrive - University of Leeds\\New folder\\nirs-resources-main\\syntheticNIRS\\RESOD2_struct_noiselevel2_file2.mat\"\n",
    "\n",
    "# === Load both .mat files\n",
    "mat1 = scipy.io.loadmat(file1_path)\n",
    "mat2 = scipy.io.loadmat(file2_path)\n",
    "\n",
    "print(\"File 1 keys:\", mat1.keys())\n",
    "print(\"File 2 keys:\", mat2.keys())\n",
    "\n",
    "# Get the real sampling frequency from your actual recording\n",
    "real_sfreq_file1 = participant_od_final[\"participant_1\"][0].info['sfreq']\n",
    "real_sfreq_file2 = participant_od_final[\"participant_1\"][1].info['sfreq']\n",
    "\n",
    "def build_raw_from_struct(mat, sfreq, title):\n",
    "    od_data = mat['data'].T\n",
    "    times = mat['time'].flatten()\n",
    "\n",
    "    probe = mat['probe'][0, 0]\n",
    "    link = probe['link'][0, 0]\n",
    "\n",
    "    src = link['source'].flatten()\n",
    "    det = link['detector'].flatten()\n",
    "    wl  = link['type'].flatten()\n",
    "\n",
    "    ch_names = [f\"S{src[i]}_D{det[i]} {wl[i]}\" for i in range(len(src))]\n",
    "\n",
    "    info = create_info(ch_names=ch_names, sfreq=sfreq, ch_types='fnirs_od')\n",
    "    raw = RawArray(od_data, info)\n",
    "\n",
    "    print(raw)\n",
    "    raw.plot(n_channels=10, title=title)\n",
    "    return raw\n",
    "\n",
    "\n",
    "# === Build Raw objects\n",
    "synthetic_raw_file1 = build_raw_from_struct(mat1, sfreq=real_sfreq_file1, title=\"Synthetic OD ‚Äì File 1\")\n",
    "synthetic_raw_file2 = build_raw_from_struct(mat2, sfreq=real_sfreq_file2, title=\"Synthetic OD ‚Äì File 2\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5a0e1-74db-4e7a-a796-7d5e701b19ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîπ Real File 1 channels:\")\n",
    "print(participant_od_final[\"participant_1\"][0].ch_names)\n",
    "\n",
    "print(\"\\nüî∏ Synthetic File 1 channels:\")\n",
    "print(synthetic_raw_file1.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c33b30-f54d-4de0-ab68-58a185217b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_raw_file1 = synthetic_raw_file1.copy().reorder_channels(\n",
    "    participant_od_final[\"participant_1\"][0].ch_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed26bc-8709-4e4d-80f2-14f96f656613",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_raw_file2 = synthetic_raw_file2.copy().reorder_channels(\n",
    "    participant_od_final[\"participant_1\"][1].ch_names\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c098e2-bc87-4e9a-b7b2-bce7bf68d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert participant_od_final[\"participant_1\"][0].ch_names == synthetic_raw_file1.ch_names\n",
    "assert participant_od_final[\"participant_1\"][1].ch_names == synthetic_raw_file2.ch_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13395c9e-f870-4972-9f30-a0a6ee159793",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Real File 1 sfreq:\", participant_od_final[\"participant_1\"][0].info['sfreq'])\n",
    "print(\"Synthetic File 1 sfreq:\", synthetic_raw_file1.info['sfreq'])\n",
    "\n",
    "print(\"Real File 2 sfreq:\", participant_od_final[\"participant_1\"][1].info['sfreq'])\n",
    "print(\"Synthetic File 2 sfreq:\", synthetic_raw_file2.info['sfreq'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a3a07-da41-4000-83ec-cb6981af7cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert real data to RawArray\n",
    "real_raw1 = participant_od_final[\"participant_1\"][0]\n",
    "real_data1, _ = real_raw1.get_data(return_times=True)\n",
    "info1 = real_raw1.info.copy()\n",
    "real_raw_array1 = RawArray(real_data1, info1)\n",
    "\n",
    "real_raw2 = participant_od_final[\"participant_1\"][1]\n",
    "real_data2, _ = real_raw2.get_data(return_times=True)\n",
    "info2 = real_raw2.info.copy()\n",
    "real_raw_array2 = RawArray(real_data2, info2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1971b2ac-f791-4067-96ec-18d3d9de2692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne import concatenate_raws\n",
    "\n",
    "extended_file1 = concatenate_raws([real_raw_array1, synthetic_raw_file1])\n",
    "extended_file2 = concatenate_raws([real_raw_array2, synthetic_raw_file2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c24e9-056a-49f1-90fb-7ce8379e7368",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_od_final[\"participant_1\"][0] = extended_file1\n",
    "participant_od_final[\"participant_1\"][1] = extended_file2\n",
    "print(\"Extended File 1 duration (sec):\", participant_od_final[\"participant_1\"][0].times[-1])\n",
    "print(\"Extended File 2 duration (sec):\", participant_od_final[\"participant_1\"][1].times[-1])\n",
    "print(\"File 1: n_times =\", participant_od_final[\"participant_1\"][0].n_times)\n",
    "print(\"sfreq =\", participant_od_final[\"participant_1\"][0].info['sfreq'])\n",
    "print(\"duration (computed) =\", participant_od_final[\"participant_1\"][0].n_times / participant_od_final[\"participant_1\"][0].info['sfreq'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321cca7-66a1-4956-8ad0-af1b45b34477",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_od_final[\"participant_1\"][0].save(\"participant1_file1_extended_raw.fif\", overwrite=True)\n",
    "participant_od_final[\"participant_1\"][1].save(\"participant1_file2_extended_raw.fif\", overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fa0ee1-06e7-4d86-bfd5-d0f1d3378741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mne.preprocessing.nirs import beer_lambert_law\n",
    "for participant, recordings in participant_od_final.items():\n",
    "    hb_list = []\n",
    "\n",
    "    for i, raw_od in enumerate(recordings):\n",
    "        if participant == \"participant_1\" and i in [0, 1]:\n",
    "            raw_od = participant_od_final[participant][i]  # already extended\n",
    "\n",
    "        # ‚úÖ Step 1: Convert OD to Hb\n",
    "        raw_hb = beer_lambert_law(raw_od)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a38a4d-9572-4036-aca7-4226419dd2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def plot_sd_pairs_hbo_hbr(raw_hb, attention_start=34.5, attention_end=76.5, max_pairs=None):\n",
    "    data, times = raw_hb.get_data(return_times=True)\n",
    "    ch_names = raw_hb.ch_names\n",
    "\n",
    "    # Group HbO/HbR indices by source-detector pair\n",
    "    sd_pair_map = defaultdict(dict)\n",
    "    for idx, name in enumerate(ch_names):\n",
    "        parts = name.split()\n",
    "        sd_id = parts[0]  # e.g., \"S3_D4\"\n",
    "        chrom = parts[1]  # \"hbo\" or \"hbr\"\n",
    "        sd_pair_map[sd_id][chrom] = idx\n",
    "\n",
    "    plotted = 0\n",
    "    for sd_id, chrom_map in sd_pair_map.items():\n",
    "        if \"hbo\" in chrom_map and \"hbr\" in chrom_map:\n",
    "            idx_hbo = chrom_map[\"hbo\"]\n",
    "            idx_hbr = chrom_map[\"hbr\"]\n",
    "\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.plot(times, data[idx_hbo], label=f\"{sd_id} HbO\", color='red')\n",
    "            plt.plot(times, data[idx_hbr], label=f\"{sd_id} HbR\", color='blue')\n",
    "            plt.axvspan(attention_start, attention_end, color='pink', alpha=0.2, label='Attention Period')\n",
    "            plt.title(f\"Hemoglobin: {sd_id}\")\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"¬µmol/L\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            plotted += 1\n",
    "            if max_pairs is not None and plotted >= max_pairs:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5136c290-948a-4c43-be27-e764d1b0a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, raw_od in enumerate(participant_od_final[\"participant_1\"]):\n",
    "    print(f\"Participant 1 ‚Äì File {i+1}\")\n",
    "    raw_hb = beer_lambert_law(raw_od)\n",
    "    plot_sd_pairs_hbo_hbr(raw_hb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca0659-6b9d-4594-9d65-8abb5c356824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "def butter_bandpass_filter(data, sfreq, lowcut=0.001, highcut=0.2, order=3):\n",
    "    nyq = 0.5 * sfreq\n",
    "    b, a = butter(order, [lowcut / nyq, highcut / nyq], btype='band')\n",
    "    return filtfilt(b, a, data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac8f92-5d90-4da3-9b63-2bfee933b934",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_hb_final = {}\n",
    "\n",
    "for participant, recordings in participant_od_final.items():\n",
    "    hb_list = []\n",
    "\n",
    "    for i, raw_od in enumerate(recordings):\n",
    "        # 1. Convert to hemoglobin\n",
    "        raw_hb = beer_lambert_law(raw_od)\n",
    "\n",
    "        # 2. Filter\n",
    "        sfreq = raw_hb.info['sfreq']\n",
    "        filtered_data = butter_bandpass_filter(raw_hb.get_data(), sfreq)\n",
    "\n",
    "        # 3. Overwrite with filtered data\n",
    "        raw_hb._data = filtered_data\n",
    "\n",
    "        # 4. (Optional) Downsample to match Tufts\n",
    "        raw_hb.resample(5.2, npad=\"auto\")\n",
    "\n",
    "        hb_list.append(raw_hb)\n",
    "\n",
    "    participant_hb_final[participant] = hb_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec568ee-fa45-438e-a061-3f824ab08188",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant, files in participant_hb_final.items():\n",
    "    print(f\"\\n=== {participant} ===\")\n",
    "    for i, raw in enumerate(files):\n",
    "        sfreq = raw.info['sfreq']\n",
    "        duration = raw.times[-1]\n",
    "        print(f\"File {i+1}: sfreq = {sfreq:.2f} Hz | Duration = {duration:.2f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2428261-ee59-439d-b8ef-5170fd889d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sliding_windows(raw_data, window_size=93, step_size=3):\n",
    "    \"\"\"\n",
    "    Extract overlapping 18s sliding windows from raw fNIRS data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_data : ndarray, shape (n_channels, n_times)\n",
    "    window_size : int\n",
    "        Number of time points per window (93 for 18s @ 5.2Hz)\n",
    "    step_size : int\n",
    "        Number of samples to shift between windows (3 for 0.6s stride)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    windows : ndarray, shape (n_windows, window_size, n_channels)\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    n_channels, n_times = raw_data.shape\n",
    "    for start in range(0, n_times - window_size + 1, step_size):\n",
    "        window = raw_data[:, start:start + window_size].T  # shape (93, n_channels)\n",
    "        windows.append(window)\n",
    "    return np.stack(windows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd148b28-7f70-4114-b61c-775f38855195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set correct window size for 18s @ 5.2 Hz\n",
    "WINDOW_SIZE = int(18 * 5.2)  # 93 samples\n",
    "STRIDE = int(0.6 * 5.2)      # 3 samples\n",
    "\n",
    "all_windows = {}\n",
    "for participant, recordings in participant_hb_final.items():\n",
    "    participant_windows = []\n",
    "    for i, raw_hb in enumerate(recordings):\n",
    "        raw_data = raw_hb.get_data()  # shape: (n_channels, n_times)\n",
    "        windows = extract_sliding_windows(raw_data, window_size=WINDOW_SIZE, step_size=STRIDE)\n",
    "        participant_windows.append(windows)  # shape: (n_windows, 93, n_channels)\n",
    "    all_windows[participant] = participant_windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cdb827-eefb-4981-a09a-91f34a2d1693",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant, windows_list in all_windows.items():\n",
    "    print(f\"\\n=== {participant} ===\")\n",
    "    for i, windows in enumerate(windows_list):\n",
    "        print(f\"File {i+1}: shape = {windows.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc20da17-8b62-4674-bfca-f9cb3d6de378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_windows(recording_durations, window_size_sec=18, stride_sec=0.6):\n",
    "    ...\n",
    "\n",
    "    labels_by_participant = {}\n",
    "\n",
    "    for participant, file_durations in recording_durations.items():\n",
    "        labels_by_file = []\n",
    "\n",
    "        for i, duration in enumerate(file_durations):\n",
    "            n_windows = int((duration - window_size_sec) / stride_sec) + 1\n",
    "            labels = []\n",
    "\n",
    "            for w in range(n_windows):\n",
    "                window_end = w * stride_sec + window_size_sec  # Tufts-style: use endpoint only\n",
    "\n",
    "                # Define attention windows\n",
    "                if participant == \"participant_1\" and i == 0:\n",
    "                    attention_start, attention_end = 34.5, 52.22\n",
    "                elif participant == \"participant_1\" and i == 1:\n",
    "                    attention_start, attention_end = 34.5, 47.81\n",
    "                else:\n",
    "                    attention_start, attention_end = 34.5, 76.5\n",
    "\n",
    "                # Label based on whether window END falls in attention\n",
    "                if attention_start <= window_end <= attention_end:\n",
    "                    labels.append(1)\n",
    "                else:\n",
    "                    labels.append(0)\n",
    "\n",
    "            labels_by_file.append(labels)\n",
    "        labels_by_participant[participant] = labels_by_file\n",
    "\n",
    "    return labels_by_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9e9e69-3e38-4858-b4a8-7d97c3aed0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_durations = {\n",
    "    \"participant_1\": [76.35, 76.35, 119.23, 92.12],\n",
    "    \"participant_2\": [129.62, 91.73, 96.92, 80.38],\n",
    "    \"participant_3\": [86.73, 97.50, 87.88, 92.69]\n",
    "}\n",
    "\n",
    "labels_all = label_windows(recording_durations)  # ‚úÖ call the function\n",
    "\n",
    "participant = \"participant_1\"\n",
    "file_idx = 0\n",
    "windows = all_windows[participant][file_idx]\n",
    "labels = labels_all[participant][file_idx]  # ‚úÖ use the result of the function\n",
    "\n",
    "# Plot the last 5 windows\n",
    "for idx in range(len(labels) - 5, len(labels)):\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    plt.plot(windows[idx][:, 0], color='purple')  # channel 0 (HbO or HbR)\n",
    "    plt.title(f\"Window {idx} ‚Äì Label: {labels[idx]}\")\n",
    "    plt.xlabel(\"Time points (at 5.2 Hz)\")\n",
    "    plt.ylabel(\"Signal\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Print end times and labels\n",
    "for idx in range(len(labels)):\n",
    "    end_time = idx * 0.6 + 18\n",
    "\n",
    "    print(f\"Window {idx} | Ends at ~{end_time:.1f}s | Label: {labels[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47623ad-f8ef-4b9e-a894-723f1daf69fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "participant = \"participant_1\"\n",
    "file_idx = 0\n",
    "\n",
    "windows = all_windows[participant][file_idx]  # shape: (n_windows, 93, 8)\n",
    "labels = labels_all[participant][file_idx]     # list of 0s and 1s\n",
    "stride = 3  # samples\n",
    "fs = 5.2    # Hz\n",
    "\n",
    "# Reconstruct continuous time series from overlapping windows\n",
    "# Use the center of each window for plotting\n",
    "signal = windows[:, :, 0]  # channel 0, shape: (n_windows, 93)\n",
    "window_centers = np.arange(len(windows)) * stride + (93 // 2)\n",
    "time_axis = window_centers / fs  # in seconds\n",
    "center_values = signal[:, 93 // 2]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.plot(time_axis, center_values, label='Channel 0 (center of each window)', color='purple')\n",
    "\n",
    "# Add shaded label regions\n",
    "for i in range(len(labels)):\n",
    "    start_time = (i * stride) / fs\n",
    "    end_time = (i * stride + 93) / fs\n",
    "    color = 'red' if labels[i] == 1 else 'gray'\n",
    "    plt.axvspan(start_time, end_time, alpha=0.15, color=color)\n",
    "\n",
    "plt.title(\"Signal from Channel 0 with Window Labels (Gray = Rest, Red = Attention)\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Signal (HbO/HbR)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55a7a34-6f66-403a-86eb-785bcb5802f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_8_channels(raw, selected_pairs):\n",
    "    selected_chs = []\n",
    "    for ch_name in raw.ch_names:\n",
    "        for pair in selected_pairs:\n",
    "            if pair in ch_name and ('hbo' in ch_name or 'hbr' in ch_name):\n",
    "                selected_chs.append(ch_name)\n",
    "    return raw.copy().pick_channels(selected_chs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110c649-389d-4348-8165-bc3f244e447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_pairs = ['S3_D3', 'S4_D4', 'S6_D6', 'S8_D6']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b0b64-3ec0-4ca4-9bff-c8439a53bd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_hb_selected = {}\n",
    "\n",
    "for participant, recordings in participant_hb_final.items():\n",
    "    selected_list = []\n",
    "    for raw in recordings:\n",
    "        selected_raw = select_8_channels(raw, selected_pairs)\n",
    "        selected_list.append(selected_raw)\n",
    "    participant_hb_selected[participant] = selected_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a7b708-ce76-4c15-bd2e-12f5858c48b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant, files in participant_hb_selected.items():\n",
    "    print(f\"\\n{participant}\")\n",
    "    for i, raw in enumerate(files):\n",
    "        print(f\"File {i+1}: {len(raw.ch_names)} channels ‚Üí {raw.ch_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab531b-6409-4a93-9b26-3c371831d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sliding_windows(raw_data, window_size=93, step_size=3):\n",
    "\n",
    "    windows = []\n",
    "    n_channels, n_times = raw_data.shape\n",
    "    for start in range(0, n_times - window_size + 1, step_size):\n",
    "        window = raw_data[:, start:start + window_size].T  # shape (93, n_channels)\n",
    "        windows.append(window)\n",
    "    return np.stack(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a6f734-68a0-45fc-ac4d-48a76389aa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set correct window size for 18s @ 5.2 Hz\n",
    "WINDOW_SIZE = int(18 * 5.2)  # 93 samples\n",
    "STRIDE = int(0.6 * 5.2)      # 3 samples\n",
    "\n",
    "all_windows = {}\n",
    "for participant, recordings in participant_hb_selected.items():\n",
    "    participant_windows = []\n",
    "    for i, raw_hb in enumerate(recordings):\n",
    "        raw_data = raw_hb.get_data()  # shape: (n_channels, n_times)\n",
    "        windows = extract_sliding_windows(raw_data, window_size=WINDOW_SIZE, step_size=STRIDE)\n",
    "        participant_windows.append(windows)  # shape: (n_windows, 93, n_channels)\n",
    "    all_windows[participant] = participant_windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9086a009-46ce-4198-930d-a3f72a2cdef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all = label_windows(recording_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33105a9-15e6-4066-b50b-13d85a38ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant in all_windows:\n",
    "    print(f\"\\n{participant}\")\n",
    "    for i in range(4):\n",
    "        print(f\"File {i+1}: {all_windows[participant][i].shape[0]} windows | {len(labels_all[participant][i])} labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c143d-a411-4b8a-9fc3-329d9ccf0d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Step 1: Combine all windows and labels\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "for participant in all_windows:\n",
    "    for i in range(len(all_windows[participant])):\n",
    "        windows = all_windows[participant][i]\n",
    "        labels = labels_all[participant][i]\n",
    "\n",
    "        # Trim to match\n",
    "        min_len = min(len(windows), len(labels))\n",
    "        windows = windows[:min_len]\n",
    "        labels = labels[:min_len]\n",
    "\n",
    "        X_list.append(windows)\n",
    "        y_list.append(labels)\n",
    "\n",
    "# Step 2: Convert to arrays\n",
    "X = np.vstack(X_list)  # Shape: (N, 150, 8)\n",
    "y = np.hstack(y_list)  # Shape: (N,)\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Label counts:\", np.bincount(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea097e4-aaef-4c95-a968-8b78789c9e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.data.core import TSTensor\n",
    "\n",
    "X_test = np.transpose(X, (0, 2, 1)).astype(np.float32)\n",
    "X_test = TSTensor(X_test)\n",
    "print(X_test.shape)  # should now be (1285, 8, 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603760c-a583-4d78-a902-a811e87232dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "# Patch to avoid PosixPath error on Windows\n",
    "if sys.platform == \"win32\":\n",
    "    pathlib.PosixPath = pathlib.WindowsPath\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf098d-fc7b-4a50-8711-05e1dc5409b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.all import *\n",
    "\n",
    "# Use raw string (r\"...\") or escape backslashes\n",
    "model_path = r\"C:\\Users\\xtwf7586\\OneDrive - University of Leeds\\fnirs\\AuditoryRecording13032025\\models\\models\\LSTM_Tufts_Ccclean18.pkl\"\n",
    "learn = load_learner(model_path)\n",
    "\n",
    "print(\"‚úÖ Loaded:\", learn.model.__class__.__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2038e654-f1ba-4255-ac9a-c6f5098a7382",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.all import *\n",
    "import numpy as np\n",
    "from tsai.data.core import TSTensor\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# 3) Get predictions ‚Äî handle variable return lengths across tsai versions\n",
    "res = learn.get_X_preds(X_test, y=y, bs=128)\n",
    "# res can be (probs, targs) or (probs, targs, decoded) or (probs, targs, decoded, losses)\n",
    "probs = res[0]\n",
    "targs = res[1] if len(res) > 1 else None\n",
    "\n",
    "# 4) Metrics (use your y directly if targs is None)\n",
    "preds_class = probs.argmax(1).cpu().numpy()\n",
    "true_y = y if targs is None else targs.cpu().numpy()\n",
    "\n",
    "print(\"‚úÖ Accuracy:\", accuracy_score(true_y, preds_class))\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(true_y, preds_class))\n",
    "print(\"\\nüîç Confusion Matrix:\")\n",
    "print(confusion_matrix(true_y, preds_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90889c1b-4dd5-4ebe-bab3-2423d953dff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(true_y, preds_class)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Class 0', 'Class 1'],\n",
    "            yticklabels=['Class 0', 'Class 1'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c805882-6cb3-4790-920a-76ac1ea252db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X shape:\", X.shape)  # should be (samples, 93, 8)\n",
    "print(\"y shape:\", y.shape)  # should be (samples,)\n",
    "print(\"X dtype:\", X.dtype)  # should be float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b236c-e526-48d5-88cc-50a4e7814a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0f5a0-3c08-4041-a651-7288e8f0e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Standardize (match training)\n",
    "X_mean = X.mean(axis=(0, 1), keepdims=True)\n",
    "X_stddev = X.std(axis=(0, 1), keepdims=True)\n",
    "X_std = (X - X_mean) / X_stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33a9a72-bdd9-4192-abbf-1b606babd6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Predict\n",
    "preds_raw, _, _ = learn.get_X_preds(X_std)\n",
    "preds_class = np.argmax(preds_raw, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81f684-f4c9-493a-9261-e35aee522702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluate\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"‚úÖ Accuracy:\", accuracy_score(y, preds_class))\n",
    "print(\"\\nüìä Classification Report:\")\n",
    "print(classification_report(y, preds_class, target_names=[\"Rest\", \"Attention\"]))\n",
    "print(\"\\nüîç Confusion Matrix:\")\n",
    "print(confusion_matrix(y, preds_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7530d055-80b9-4160-9d14-d07dfade8022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# X_std = your standardized input (shape: n_samples, 93, 8)\n",
    "# y = true labels (binary)\n",
    "# preds_class = predicted labels (from get_X_preds)\n",
    "\n",
    "# Just in case\n",
    "assert len(y) == len(preds_class), \"Mismatch in prediction and label lengths\"\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "\n",
    "plt.plot(y, label='True Label', linewidth=2, alpha=0.7)\n",
    "plt.plot(preds_class, label='Predicted Label', linestyle='dashed', alpha=0.7)\n",
    "\n",
    "plt.xlabel(\"Window Index\")\n",
    "plt.ylabel(\"Label (0 = Rest, 1 = Attention)\")\n",
    "plt.title(\"üß† Model Predictions vs True Labels Over Time\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a286eb5-80f1-477d-9744-258a4aaceb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train/val split (random)\n",
    "X_cf = np.transpose(X, (0, 2, 1)).astype(np.float32)\n",
    "train_idx, val_idx = train_test_split(np.arange(len(y)), test_size=0.2, random_state=42, stratify=y)\n",
    "splits = (list(train_idx), list(val_idx))\n",
    "\n",
    "# Slice from X_cf instead of X\n",
    "X_train, X_val = X_cf[splits[0]], X_cf[splits[1]]\n",
    "y_train, y_val = y[splits[0]], y[splits[1]]\n",
    "\n",
    "print(\"Train data shape:\", X_train.shape)\n",
    "print(\"Validation data shape:\", X_val.shape)\n",
    "print(\"Train label counts:\", np.bincount(y_train))\n",
    "print(\"Validation label counts:\", np.bincount(y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee33aa46-a923-4124-b958-78e5f127e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.all import *\n",
    "from fastai.callback.all import SaveModelCallback\n",
    "\n",
    "# Define transforms\n",
    "tfms = [None, [Categorize()]]\n",
    "batch_tfms = TSStandardize(by_sample=True)\n",
    "\n",
    "# Create datasets with splits\n",
    "dsets = TSDatasets(X_cf, y, tfms=tfms, splits=splits, inplace=True)\n",
    "\n",
    "# Create DataLoaders\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=[TSStandardize()], num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72afe669-a39d-4e71-8018-848a9e1a9f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.callback.all import SaveModelCallback\n",
    "\n",
    "mv_clf = TSClassifier(\n",
    "    X_cf, y, splits=splits,\n",
    "    arch=LSTM, arch_config={'n_layers': 3, 'bidirectional': True},\n",
    "    tfms=tfms, batch_tfms=batch_tfms,\n",
    "    metrics=accuracy,\n",
    "    path='models',\n",
    "    cbs=ShowGraph()\n",
    ")\n",
    "\n",
    "# Train it\n",
    "mv_clf.fit_one_cycle(20, 1e-3)  # 1e-3 is safer for LSTM, but you can match Tufts exactly\n",
    "\n",
    "# Export the trained model\n",
    "mv_clf.save('own_final18')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5721c788-f963-4b7e-b63d-ec7cdd887b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions and true labels on the training set\n",
    "all_preds = mv_clf.get_X_preds(X_train, y_train, with_input=False)\n",
    "preds = all_preds[0]   # shape: (n_samples, n_classes)\n",
    "targets = all_preds[1] # shape: (n_samples,)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_acc = accuracy_score(targets, preds.argmax(axis=1))\n",
    "print(f\"‚úÖ Training accuracy: {train_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1218f1-014d-4d13-8779-31e779077e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = mv_clf.get_X_preds(X_val, y_val, with_input=False)\n",
    "val_acc = accuracy_score(val_preds[1], val_preds[0].argmax(axis=1))\n",
    "print(f\"‚úÖ Validation accuracy: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad822d9b-f602-4725-9f7e-55e3a38af946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get predictions on the validation split (ds_idx=1)\n",
    "preds, targs = mv_clf.get_preds(ds_idx=1)   # returns torch tensors\n",
    "\n",
    "y_val_pred = preds.argmax(1).cpu().numpy()\n",
    "y_val_true = targs.cpu().numpy()\n",
    "\n",
    "print(\"Val accuracy:\", accuracy_score(y_val_true, y_val_pred))\n",
    "print(classification_report(y_val_true, y_val_pred, digits=3))\n",
    "\n",
    "cm = confusion_matrix(y_val_true, y_val_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues', xticks_rotation=0)\n",
    "plt.title(\"Validation Confusion Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83cc3e-e606-463e-8284-9b3e2a6b430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsai.all import *\n",
    "\n",
    "# Step 1: Define your model exactly as before\n",
    "# ‚úÖ Correct:\n",
    "model = create_model(LSTM, c_in=8, c_out=2, seq_len=150, arch_config={'n_layers': 3, 'bidirectional': True})\n",
    "\n",
    "# Step 2: Create dummy dataloaders (for export only)\n",
    "def get_dummy_dl(seq_len=150, n_vars=8, n_classes=2):\n",
    "    X_dummy = np.random.randn(2, 8, 150).astype(np.float32)\n",
    "    y_dummy = np.array([0, 1])\n",
    "    tfms = [None, [Categorize()]]\n",
    "    dsets = TSDatasets(X_dummy, y_dummy, tfms=tfms)\n",
    "    return TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=2)\n",
    "\n",
    "dls = get_dummy_dl()\n",
    "\n",
    "# ‚úÖ Step 3: Load your trained weights using the correct path\n",
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    metrics=accuracy,\n",
    "    path='models/models',   # ‚úÖ This is the folder containing your .pth\n",
    "    model_dir='.'           # ‚úÖ Because the .pth file is directly inside it\n",
    ")\n",
    "\n",
    "# ‚úÖ Step 4: Load and export\n",
    "learn.load('own_final18')  # Will now correctly find and load the weights\n",
    "learn.export('LSTM_final18_clean_export.pkl')  # ‚úÖ Clean, inference-ready export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3f8224-f1f1-4b1c-8a2d-2f83927b96ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "export_path = Path(learn.path) / learn.model_dir / \"LSTM_final18_clean_export.pkl\"\n",
    "print(\"‚úÖ Model exported to:\", export_path)\n",
    "print(\"‚úÖ File exists?\", export_path.exists())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
